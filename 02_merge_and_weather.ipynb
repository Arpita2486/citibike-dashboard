{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d8ff93-96bd-4c08-b06f-89abee8747d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " ['202201-citibike-tripdata.zip',\n",
       "  '202202-citibike-tripdata.zip',\n",
       "  '202203-citibike-tripdata.zip'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(r\"C:\\Users\\arpit\\Documents\\CareerFoundry\\Python_dashboard\\citibike-dashboard\\Data\\2022-citibike-tripdata\\2022-citibike-tripdata\")\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\arpit\\Documents\\CareerFoundry\\Python_dashboard\\citibike-dashboard\\Output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# look for all .zip files in that folder\n",
    "zip_files = sorted(DATA_DIR.glob(\"*.zip\"))\n",
    "len(zip_files), [z.name for z in zip_files[:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854a535e-ed15-4cc4-b3cb-d217d350dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, zipfile\n",
    "\n",
    "def read_citibike_zip(zippath: Path) -> pd.DataFrame:\n",
    "    with zipfile.ZipFile(zippath) as zf:\n",
    "        csv_members = [m for m in zf.namelist() if m.lower().endswith(\".csv\")]\n",
    "        if not csv_members:\n",
    "            raise FileNotFoundError(f\"No CSV found inside {zippath.name}\")\n",
    "        with zf.open(csv_members[0]) as f:\n",
    "            df = pd.read_csv(f, low_memory=False)\n",
    "\n",
    "    # normalize started_at\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    if \"started_at\" not in df.columns:\n",
    "        for cand in (\"starttime\",\"start_time\",\"started at\"):\n",
    "            if cand in lower:\n",
    "                df.rename(columns={lower[cand]: \"started_at\"}, inplace=True)\n",
    "                break\n",
    "    if \"started_at\" not in df.columns:\n",
    "        raise KeyError(f\"'started_at' not found in {zippath.name}\")\n",
    "\n",
    "    df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], errors=\"coerce\", utc=True)\n",
    "    df[\"date\"] = df[\"started_at\"].dt.date\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3240a386-8604-4b86-a66a-bf8773f0f03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 202201-citibike-tripdata.zip\n",
      "Reading: 202202-citibike-tripdata.zip\n",
      "Reading: 202203-citibike-tripdata.zip\n",
      "Reading: 202204-citibike-tripdata.zip\n",
      "Reading: 202205-citibike-tripdata.zip\n",
      "Reading: 202206-citibike-tripdata.zip\n",
      "Reading: 202207-citibike-tripdata.zip\n",
      "Reading: 202208-citibike-tripdata.zip\n",
      "Reading: 202209-citibike-tripdata.zip\n",
      "Reading: 202210-citibike-tripdata.zip\n",
      "Reading: 202211-citibike-tripdata.zip\n",
      "Reading: 202212-citibike-tripdata.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8878119, 14),\n",
       "             ride_id  rideable_type                       started_at  \\\n",
       " 0  63AF72AB3CD47753   classic_bike 2022-01-13 21:36:47.689000+00:00   \n",
       " 1  9C0DAD8C1E0EA571   classic_bike 2022-01-16 17:56:23.889000+00:00   \n",
       " 2  9576DDD8920974F5  electric_bike 2022-01-18 07:10:04.799000+00:00   \n",
       " 3  962A466CC3AC6781   classic_bike 2022-01-22 12:10:10.225000+00:00   \n",
       " 4  C2585407BA0FE3E9   classic_bike 2022-01-08 16:35:16.497000+00:00   \n",
       " \n",
       "                   ended_at                start_station_name start_station_id  \\\n",
       " 0  2022-01-13 21:46:02.024                   5 Ave & E 63 St          6904.06   \n",
       " 1  2022-01-16 18:03:50.269  Grand Army Plaza & Plaza St West          4010.15   \n",
       " 2  2022-01-18 07:20:54.450                  W 20 St & 10 Ave          6306.01   \n",
       " 3  2022-01-22 12:20:06.899                   W 54 St & 9 Ave          6920.03   \n",
       " 4  2022-01-08 16:45:33.279              Sharon St & Olive St          5323.05   \n",
       " \n",
       "               end_station_name end_station_id  start_lat  start_lng  \\\n",
       " 0           Broadway & W 51 St        6779.04  40.766368 -73.971518   \n",
       " 1  Bedford Ave & Montgomery St        3736.03  40.672968 -73.970880   \n",
       " 2           Broadway & W 51 St        6779.04  40.745686 -74.005141   \n",
       " 3             10 Ave & W 28 St        6459.04  40.765849 -73.986905   \n",
       " 4      Driggs Ave & Lorimer St        5481.04  40.715353 -73.938560   \n",
       " \n",
       "      end_lat    end_lng member_casual        date  \n",
       " 0  40.762288 -73.983362        member  2022-01-13  \n",
       " 1  40.665816 -73.956934        member  2022-01-16  \n",
       " 2  40.762288 -73.983362        member  2022-01-18  \n",
       " 3  40.750664 -74.001768        member  2022-01-22  \n",
       " 4  40.721791 -73.950415        casual  2022-01-08  )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_months = []\n",
    "for zp in zip_files:\n",
    "    print(\"Reading:\", zp.name)\n",
    "    mdf = read_citibike_zip(zp)\n",
    "    all_months.append(mdf)\n",
    "\n",
    "df_2022 = pd.concat(all_months, ignore_index=True)\n",
    "df_2022.shape, df_2022.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2fa598e-3101-4977-b485-53e001f3ca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste your NOAA token here (input is hidden):  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved token to: C:\\Users\\arpit\\Documents\\CareerFoundry\\Python_dashboard\\citibike-dashboard\\.env\n",
      "Has token: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# set your repo root (adjust only if your path is different)\n",
    "repo_root = Path(r\"C:\\Users\\arpit\\Documents\\CareerFoundry\\Python_dashboard\\citibike-dashboard\")\n",
    "\n",
    "# prompt for your NOAA token (input is hidden)\n",
    "token = getpass(\"Paste your NOAA token here (input is hidden): \")\n",
    "\n",
    "# set env var for this notebook session\n",
    "os.environ[\"NOAA_TOKEN\"] = token\n",
    "\n",
    "# also save a .env file for later use (safe to keep locally; don't push it)\n",
    "(env_path := repo_root / \".env\").write_text(f\"NOAA_TOKEN={token}\\n\", encoding=\"utf-8\")\n",
    "print(f\" Saved token to: {env_path}\")\n",
    "print(\"Has token:\", bool(os.getenv(\"NOAA_TOKEN\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22efc26-a843-428d-aec2-9e11ae00f26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 monthly ZIPs for 2022. First 3: ['202201-citibike-tripdata.zip', '202202-citibike-tripdata.zip', '202203-citibike-tripdata.zip']\n",
      "Reading: 202201-citibike-tripdata.zip\n",
      "Reading: 202202-citibike-tripdata.zip\n",
      "Reading: 202203-citibike-tripdata.zip\n",
      "Reading: 202204-citibike-tripdata.zip\n",
      "Reading: 202205-citibike-tripdata.zip\n",
      "Reading: 202206-citibike-tripdata.zip\n",
      "Reading: 202207-citibike-tripdata.zip\n",
      "Reading: 202208-citibike-tripdata.zip\n",
      "Reading: 202209-citibike-tripdata.zip\n",
      "Reading: 202210-citibike-tripdata.zip\n",
      "Reading: 202211-citibike-tripdata.zip\n",
      "Reading: 202212-citibike-tripdata.zip\n",
      "Trips combined shape: (8878119, 14)\n",
      "Weather days: 365\n",
      "Merged shape: (8878119, 15)\n",
      "Saved sample CSV: C:\\Users\\arpit\\Documents\\CareerFoundry\\Python_dashboard\\citibike-dashboard\\Output\\citibike_weather_2022_sample_100k.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>date</th>\n",
       "      <th>avgTemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7684352</th>\n",
       "      <td>55D8341CBE041629</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-11-18 07:22:57.286000+00:00</td>\n",
       "      <td>2022-11-18 07:24:51.457</td>\n",
       "      <td>1 Ave &amp; E 6 St</td>\n",
       "      <td>5626.15</td>\n",
       "      <td>E 6 St &amp; Avenue B</td>\n",
       "      <td>5584.04</td>\n",
       "      <td>40.726331</td>\n",
       "      <td>-73.986169</td>\n",
       "      <td>40.724537</td>\n",
       "      <td>-73.981854</td>\n",
       "      <td>member</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6968415</th>\n",
       "      <td>B82C3CD4A7162310</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-10-30 14:58:04.899000+00:00</td>\n",
       "      <td>2022-10-30 15:37:46.486</td>\n",
       "      <td>West St &amp; Liberty St</td>\n",
       "      <td>5184.08</td>\n",
       "      <td>11 Ave &amp; W 59 St</td>\n",
       "      <td>7059.01</td>\n",
       "      <td>40.711444</td>\n",
       "      <td>-74.014847</td>\n",
       "      <td>40.771497</td>\n",
       "      <td>-73.990460</td>\n",
       "      <td>casual</td>\n",
       "      <td>2022-10-30</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397215</th>\n",
       "      <td>05DE7F6CC9C07083</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-12-07 20:01:14.344000+00:00</td>\n",
       "      <td>2022-12-07 20:10:56.276</td>\n",
       "      <td>E 78 St &amp; 2 Ave</td>\n",
       "      <td>7057.07</td>\n",
       "      <td>Grand Army Plaza &amp; Central Park S</td>\n",
       "      <td>6839.10</td>\n",
       "      <td>40.772797</td>\n",
       "      <td>-73.955778</td>\n",
       "      <td>40.764397</td>\n",
       "      <td>-73.973715</td>\n",
       "      <td>member</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208529</th>\n",
       "      <td>AD2E356505F570DF</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-15 13:57:18.129000+00:00</td>\n",
       "      <td>2022-09-15 14:05:34.197</td>\n",
       "      <td>Suffolk St &amp; Stanton St</td>\n",
       "      <td>5445.02</td>\n",
       "      <td>Ave A &amp; E 14 St</td>\n",
       "      <td>5779.11</td>\n",
       "      <td>40.720525</td>\n",
       "      <td>-73.985271</td>\n",
       "      <td>40.730311</td>\n",
       "      <td>-73.980472</td>\n",
       "      <td>member</td>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232252</th>\n",
       "      <td>2E33A57760B13F8C</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-08-31 16:23:49.261000+00:00</td>\n",
       "      <td>2022-08-31 16:51:49.143</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>Dock St &amp; Front St</td>\n",
       "      <td>4903.09</td>\n",
       "      <td>40.717661</td>\n",
       "      <td>-74.013138</td>\n",
       "      <td>40.702709</td>\n",
       "      <td>-73.992530</td>\n",
       "      <td>casual</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ride_id  rideable_type                       started_at  \\\n",
       "7684352  55D8341CBE041629   classic_bike 2022-11-18 07:22:57.286000+00:00   \n",
       "6968415  B82C3CD4A7162310   classic_bike 2022-10-30 14:58:04.899000+00:00   \n",
       "8397215  05DE7F6CC9C07083   classic_bike 2022-12-07 20:01:14.344000+00:00   \n",
       "6208529  AD2E356505F570DF  electric_bike 2022-09-15 13:57:18.129000+00:00   \n",
       "5232252  2E33A57760B13F8C  electric_bike 2022-08-31 16:23:49.261000+00:00   \n",
       "\n",
       "                        ended_at       start_station_name start_station_id  \\\n",
       "7684352  2022-11-18 07:24:51.457           1 Ave & E 6 St          5626.15   \n",
       "6968415  2022-10-30 15:37:46.486     West St & Liberty St          5184.08   \n",
       "8397215  2022-12-07 20:10:56.276          E 78 St & 2 Ave          7057.07   \n",
       "6208529  2022-09-15 14:05:34.197  Suffolk St & Stanton St          5445.02   \n",
       "5232252  2022-08-31 16:51:49.143    West St & Chambers St          5329.03   \n",
       "\n",
       "                          end_station_name end_station_id  start_lat  \\\n",
       "7684352                  E 6 St & Avenue B        5584.04  40.726331   \n",
       "6968415                   11 Ave & W 59 St        7059.01  40.711444   \n",
       "8397215  Grand Army Plaza & Central Park S        6839.10  40.772797   \n",
       "6208529                    Ave A & E 14 St        5779.11  40.720525   \n",
       "5232252                 Dock St & Front St        4903.09  40.717661   \n",
       "\n",
       "         start_lng    end_lat    end_lng member_casual        date  avgTemp  \n",
       "7684352 -73.986169  40.724537 -73.981854        member  2022-11-18     0.45  \n",
       "6968415 -74.014847  40.771497 -73.990460        casual  2022-10-30     1.25  \n",
       "8397215 -73.955778  40.764397 -73.973715        member  2022-12-07     1.38  \n",
       "6208529 -73.985271  40.730311 -73.980472        member  2022-09-15     2.18  \n",
       "5232252 -74.013138  40.702709 -73.992530        casual  2022-08-31     2.56  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#   monthly zips merge with NOAA weather, save 100k sample\n",
    "import os, zipfile, requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from getpass import getpass\n",
    "\n",
    "# ---------- Config ----------\n",
    "YEAR = 2022\n",
    "STATION_ID = \"GHCND:USW00014732\"      # LaGuardia\n",
    "SAMPLE_ROWS = 100_000\n",
    "# ----------------------------\n",
    "\n",
    "# Detect project root (works if notebook is in Notebooks/ or repo root)\n",
    "CWD = Path.cwd().resolve()\n",
    "cands = [CWD, CWD.parent, CWD.parent.parent, CWD.parent.parent.parent]\n",
    "PROJECT_ROOT = next((p for p in cands if (p / \"Data\").exists()), CWD)\n",
    "DATA_ROOT = PROJECT_ROOT / \"Data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"Output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Find ONLY monthly zips (YYYYMM-citibike-tripdata*.zip) recursively under Data/\n",
    "all_zips = sorted(DATA_ROOT.glob(\"**/*.zip\"))\n",
    "monthly_zips = [\n",
    "    z for z in all_zips\n",
    "    if len(z.name) >= 10\n",
    "       and z.name[:6].isdigit()            # YYYYMM...\n",
    "       and \"citibike-tripdata\" in z.name.lower()\n",
    "]\n",
    "assert monthly_zips, f\"No monthly zips like YYYYMM-citibike-tripdata*.zip found under {DATA_ROOT}\"\n",
    "print(f\"Found {len(monthly_zips)} monthly ZIPs for {YEAR}. First 3:\", [z.name for z in monthly_zips[:3]])\n",
    "\n",
    "# 2) Helper to read one month ZIP; skip archives that don't actually contain a CSV\n",
    "def read_citibike_zip(zippath: Path) -> pd.DataFrame:\n",
    "    with zipfile.ZipFile(zippath) as zf:\n",
    "        csv_members = [m for m in zf.namelist() if m.lower().endswith(\".csv\")]\n",
    "        if not csv_members:\n",
    "            raise FileNotFoundError(f\"No CSV inside {zippath.name}\")\n",
    "        with zf.open(csv_members[0]) as f:\n",
    "            df = pd.read_csv(f, low_memory=False)\n",
    "\n",
    "    # normalize started_at\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    if \"started_at\" not in df.columns:\n",
    "        for cand in (\"starttime\",\"start_time\",\"started at\"):\n",
    "            if cand in lower:\n",
    "                df.rename(columns={lower[cand]: \"started_at\"}, inplace=True)\n",
    "                break\n",
    "    if \"started_at\" not in df.columns:\n",
    "        raise KeyError(f\"'started_at' not found after normalization for {zippath.name}\")\n",
    "\n",
    "    df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], errors=\"coerce\", utc=True)\n",
    "    df[\"date\"] = df[\"started_at\"].dt.date\n",
    "    return df\n",
    "\n",
    "# 3) Load & combine months (robust: skip any unexpected bad zip)\n",
    "parts = []\n",
    "for zp in monthly_zips:\n",
    "    try:\n",
    "        print(\"Reading:\", zp.name)\n",
    "        parts.append(read_citibike_zip(zp))\n",
    "    except Exception as e:\n",
    "        print(f\"!! Skipping {zp.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "df_2022 = pd.concat(parts, ignore_index=True)\n",
    "print(\"Trips combined shape:\", df_2022.shape)\n",
    "\n",
    "# 4) NOAA token: env -> .env -> prompt once (saved locally for reuse)\n",
    "token = os.getenv(\"NOAA_TOKEN\")\n",
    "if not token:\n",
    "    env_path = PROJECT_ROOT / \".env\"\n",
    "    if env_path.exists():\n",
    "        for line in env_path.read_text(encoding=\"utf-8\").splitlines():\n",
    "            if line.strip().startswith(\"NOAA_TOKEN=\"):\n",
    "                token = line.split(\"=\", 1)[1].strip()\n",
    "                break\n",
    "if not token:\n",
    "    token = getpass(\"Paste your NOAA token (hidden): \")\n",
    "    (PROJECT_ROOT / \".env\").write_text(f\"NOAA_TOKEN={token}\\n\", encoding=\"utf-8\")\n",
    "assert token, \"NOAA token missing.\"\n",
    "\n",
    "# 5) Fetch NOAA daily temps (prefer TAVG; fallback to mean(TMIN, TMAX))\n",
    "BASE_URL = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n",
    "HEADERS = {\"token\": token}\n",
    "def fetch_noaa(datatype, start, end, station=STATION_ID, limit=1000):\n",
    "    params = {\n",
    "        \"datasetid\": \"GHCND\", \"datatypeid\": datatype, \"stationid\": station,\n",
    "        \"startdate\": start, \"enddate\": end, \"limit\": limit, \"units\": \"metric\"\n",
    "    }\n",
    "    r = requests.get(BASE_URL, headers=HEADERS, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json().get(\"results\", [])\n",
    "\n",
    "start, end = f\"{YEAR}-01-01\", f\"{YEAR}-12-31\"\n",
    "res_tavg = fetch_noaa(\"TAVG\", start, end)\n",
    "\n",
    "if res_tavg:\n",
    "    dates = [it[\"date\"] for it in res_tavg]\n",
    "    vals  = [it[\"value\"] for it in res_tavg]  # tenths of °C\n",
    "    df_weather = pd.DataFrame({\n",
    "        \"date\": [datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S\").date() for x in dates],\n",
    "        \"avgTemp\": [v/10 for v in vals]\n",
    "    })\n",
    "else:\n",
    "    tmin = pd.DataFrame(fetch_noaa(\"TMIN\", start, end))\n",
    "    tmax = pd.DataFrame(fetch_noaa(\"TMAX\", start, end))\n",
    "    if tmin.empty or tmax.empty:\n",
    "        raise RuntimeError(\"NOAA returned no data for TAVG and TMIN/TMAX.\")\n",
    "    tmin[\"date\"] = pd.to_datetime(tmin[\"date\"]).dt.date\n",
    "    tmax[\"date\"] = pd.to_datetime(tmax[\"date\"]).dt.date\n",
    "    tmin[\"TMIN\"] = tmin[\"value\"].astype(float)/10.0\n",
    "    tmax[\"TMAX\"] = tmax[\"value\"].astype(float)/10.0\n",
    "    df_weather = tmin.merge(tmax, on=\"date\", how=\"outer\")\n",
    "    df_weather[\"avgTemp\"] = df_weather[[\"TMIN\", \"TMAX\"]].mean(axis=1)\n",
    "    df_weather = df_weather[[\"date\",\"avgTemp\"]]\n",
    "\n",
    "df_weather = df_weather.sort_values(\"date\").reset_index(drop=True)\n",
    "print(\"Weather days:\", len(df_weather))\n",
    "\n",
    "# 6) Merge & save a commit-friendly 100k sample\n",
    "df_merge = df_2022.merge(df_weather, how=\"left\", on=\"date\")\n",
    "sample = df_merge.sample(min(SAMPLE_ROWS, len(df_merge)), random_state=42)\n",
    "sample_path = OUTPUT_DIR / f\"citibike_weather_{YEAR}_sample_{SAMPLE_ROWS//1000}k.csv\"\n",
    "sample.to_csv(sample_path, index=False)\n",
    "\n",
    "print(\"Merged shape:\", df_merge.shape)\n",
    "print(\"Saved sample CSV:\", sample_path)\n",
    "try:\n",
    "    display(sample.head())\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebf99b-0691-4c23-98a1-080eca2211c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20c_nlp",
   "language": "python",
   "name": "20c_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
